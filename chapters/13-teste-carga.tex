% Revisão OK 30/09
\chapter{Teste de Carga}

Para avaliar a confiabilidade do projeto em cenários extremos com muitos acessos 
simultâneos, utilizou-se a framework de testes Locust. A vantagem dessa ferramenta 
é que ela é uma biblioteca Python, permitindo que, com código Python, seja possível
escrever as chamadas "tasks" \cite{locust}, que são as requisições a serem feitas.
Cada task é uma função com um decorator Python específico.

Para aumentar a confiança nos testes, as rotas são chamadas com ICAOs aleatórios.

Para garantir que os testes consultassem exclusivamente o meu servidor, coloquei 
o Cloudflare no modo de desenvolvedor, o que desativa a função de cache.

\begin{figure}[ht]
    \begin{center}
    \includegraphics[width=400pt]{img/cloudflare-dev-mode.png}
    \caption{Cache no Cloudflare desativado. Note que a linha azul está bem acima 
    da linha laranja, mostrando que meu servidor de origem está servindo as requisições}
    \label{fig:cloudflare-dev-mode}
    \end{center}
\end{figure}

O maior gargalo deste projeto era o acesso ao banco de dados. Ao testar com 500 
usuários simultâneos, no pior caso, o tempo de resposta ultrapassava 15 segundos, 
o que é totalmente inaceitável para um código de produção.

\begin{figure}[ht]
    \begin{center}
    \includegraphics[width=400pt]{img/locust-no-cache.png}
    \caption{Teste de carga no Locust}
    \label{fig:locust-no-cache}
    \end{center}
\end{figure}


Uma ideia é utilizar um banco de dados em memória, como o Redis, para fazer 
cache das respostas. Fiz um decorator Python chamado cache\_it() que verifica se
já não existe uma reposta no Redis. 

O código do decorator é o seguinte:

\begin{minipage}{\linewidth}
\lstinputlisting[label=cod:metar, title={Código do decorator de cache}, caption={Código do decorator de cache}, language=Python]{code/cache.py}
\end{minipage}

Ele é aplicado nas funções:

\begin{itemize}
    \item async def get\_info(icao):
    \item async def get\_metar(icao: str) -> tuple[str, str]:
    \item async def get\_taf(icao: str) -> tuple[str, str]:
\end{itemize}

Note que são funções que apenas recebem icao como parâmetro, então fazendo a chave
do Redis ser \verb|<ICAO>:<NOME_DA_FUNCAO>| conseguimos a unicidade. Cada chave é 
configurada apenas expirar em uma hora, mas normalmente, antes disso a função
trash\_it(icao) é chamada.

Ela remove todos os registros com chave iniciando no
icao informado no parâmetro. Todas as funções que atualizam o metar e o taf chamam
a trash\_it(). Já que estas funções atualizam informações para todos os aeródromos,
todo o cache é invalidado. Todas as funções de administração também invalidam o cache,
mas apenas para 
o aeródromo alterado. Se um ILS de SBCT, por exemplo, é alterado, todo o cache
para SBCT é invalidado.

Contudo, o teste no Locust revelou apenas uma pequena melhora principalmente no
início.

\begin{figure}[ht]
    \begin{center}
    \includegraphics[width=400pt]{img/locust-cache-redis.png}
    \caption{Teste de carga no Locust}
    \label{fig:locust-no-cache}
    \end{center}
\end{figure}

Devido a isto, 
pensou-se em uma forma de fazer cache da resposta completa. Existem bibliotecas que 
se integram com o \textit{FastAPI} como middleware, e, ao adicionar um decorador antes da
definição da rota, é possível configurar um cache com o tempo definido pelo 
programador. Contudo, essas bibliotecas não estão sendo mantidas, o que traz o 
risco de pararem de funcionar sem aviso.

Devido a este risco, optou-se por uma solução mais declarativa, em vez de implementar
algo próprio. Também queria-se ter que não depender de um servidor Python, que, por
usar uma linguagem interpretada, será mais lento que algo executado nativamente.

Como já existe o NGINX funcionando como proxy reverso, utilizou-se o próprio NGINX 
para realizar o cache das respostas. Configurou-se o cache com um tempo de um minuto, 
ou seja, no pior caso, a informação ficará desatualizada por até 1 minuto. Como 
o METAR é atualizado a cada hora, no pior cenário, alguém acessou a página com 
o METAR às 17:59:59, e essa informação seria armazenada no cache. Às 18:00:00 
sairia um novo METAR, e apenas às 18:00:59 a informação seria atualizada, o que
 é aceitável, considerando o ganho de escala.

\begin{figure}[ht]
    \begin{center}
    \includegraphics[width=400pt]{img/locust-cache.png}
    \caption{Teste de carga no Locust com cache do NGINX}
    \label{fig:locust-cache}
    \end{center}
\end{figure}